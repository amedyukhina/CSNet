{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b691a2-8022-4585-875c-81ef374c0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import UNet\n",
    "from csnet.models.csnet import CSNet\n",
    "from csnet.models.csnet_orig import CSNetOrig\n",
    "from csnet.utils.plot import plot_projections\n",
    "from csnet.utils.predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2c24d-e712-4329-977e-9c54821d75fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dir = 'data/semantic_3D/test/img'\n",
    "output_dir = 'predictions/test'\n",
    "model_path = 'model_test/dry-bush-38/best_model.pth'\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2fbe3f-852b-4a11-96a4-a7f6bf861f7a",
   "metadata": {},
   "source": [
    "### Setup and load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8edd57f-d350-45f7-8800-e1e8816edb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.dirname(model_path), 'config.json')) as f:\n",
    "    config = json.load(f)\n",
    "config = argparse.Namespace(**config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a676e-a768-40ac-a08c-91e41743034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.model.lower() == 'unet':\n",
    "    net = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=config.n_channels,\n",
    "        strides=(2,) * (len(config.n_channels) - 1),\n",
    "        num_res_units=config.num_res_units,\n",
    "        norm=Norm.BATCH,\n",
    "    )\n",
    "elif config.model.lower() == 'csnet':\n",
    "    net = CSNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=config.n_channels,\n",
    "        strides=(2,) * (len(config.n_channels) - 1),\n",
    "        num_res_units=config.num_res_units,\n",
    "        norm=Norm.BATCH,\n",
    "    )\n",
    "elif config.model.lower() == 'csnet_orig':\n",
    "    net = CSNetOrig(2, 1)\n",
    "else:\n",
    "    raise NotImplementedError(\n",
    "        rf'{config.model} is an invalid model; must be one of [\"unet\", \"csnet\", \"csnet_orig\"]')\n",
    "\n",
    "net.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad9e5ec-9513-4a56-bbdc-36a73be2a07d",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25274b51-b1ad-4248-abf0-e8f8035bba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, predicted = predict(input_dir, output_dir, net, roi_size=config.roi_size, return_last=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372e8a9b-3fbe-4223-bc19-23fbd8f2cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projections([image, predicted], panel_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26762f2c-6891-425c-9138-76b55d20f571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b4718-b7e2-40eb-8d64-5bb4050b3170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:am_pytorch]",
   "language": "python",
   "name": "conda-env-am_pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
